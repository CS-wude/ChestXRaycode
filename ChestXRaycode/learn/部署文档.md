# 胸部X光片AI分析系统 - 完整部署文档

> 版本: v1.0  
> 更新日期: 2025年1月  
> 作者: AI Medical Imaging Team

---

## 📋 目录

1. [系统概述](#系统概述)
2. [系统要求](#系统要求)
3. [开发环境部署](#开发环境部署)
4. [生产环境部署](#生产环境部署)
5. [Ollama配置](#ollama配置)
6. [功能验证](#功能验证)
7. [故障排除](#故障排除)
8. [性能优化](#性能优化)
9. [监控与维护](#监控与维护)
10. [安全配置](#安全配置)
11. [备份与恢复](#备份与恢复)
12. [FAQ](#faq)

---

## 🏥 系统概述

### 功能特性
- **AI图像分析**: 基于ResNet50的胸部X光片分类
- **双模式报告**: Ollama智能报告 + 增强版专业报告
- **Web界面**: 现代化响应式设计
- **用户选择**: 可切换报告生成方式
- **多格式支持**: PNG, JPG, JPEG, GIF, BMP, TIFF
- **报告保存**: 自动保存分析结果为JSON

### 技术架构
```
┌─────────────────────────────────────────┐
│              Web界面 (Flask)             │
├─────────────────────────────────────────┤
│          AI分析引擎                      │
│  ┌─────────────────┐ ┌─────────────────┐ │
│  │   ResNet50      │ │     Ollama      │ │
│  │   图像分类       │ │     LLM报告     │ │
│  └─────────────────┘ └─────────────────┘ │
├─────────────────────────────────────────┤
│            PyTorch Backend              │
└─────────────────────────────────────────┘
```

---

## 💻 系统要求

### 硬件要求

| 组件 | 最低配置 | 推荐配置 | 生产环境 |
|------|----------|----------|----------|
| **CPU** | 2核心 | 4核心+ | 8核心+ |
| **内存** | 4GB | 8GB+ | 16GB+ |
| **存储** | 10GB | 50GB+ | 100GB+ |
| **GPU** | 可选 | GTX 1060+ | RTX 3080+ |
| **带宽** | 10Mbps | 100Mbps+ | 1Gbps+ |

### 软件要求

| 软件 | 版本要求 | 说明 |
|------|----------|------|
| **操作系统** | Windows 10+, Ubuntu 18.04+, macOS 10.15+ | 跨平台支持 |
| **Python** | 3.7+ | 推荐3.8-3.10 |
| **pip** | 最新版 | 包管理器 |
| **Git** | 2.0+ | 版本控制 |
| **Ollama** | 最新版 | 可选LLM服务 |

---

## 🛠️ 开发环境部署

### 步骤1: 环境准备

#### 1.1 创建Python虚拟环境
```bash
# 创建虚拟环境
python -m venv pytorch_cpu_env

# 激活环境
# Windows:
pytorch_cpu_env\Scripts\activate

# Linux/macOS:
source pytorch_cpu_env/bin/activate
```

#### 1.2 升级pip
```bash
python -m pip install --upgrade pip
```

### 步骤2: 获取项目代码

```bash
# 克隆项目（如果是Git仓库）
git clone <repository-url>
cd ChestXRay/learn

# 或直接使用现有代码
cd /path/to/ChestXRay/learn
```

### 步骤3: 安装依赖

#### 3.1 安装基础依赖
```bash
# 安装PyTorch (CPU版本)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# 安装Web应用依赖
pip install -r web_requirements.txt

# 安装完整项目依赖
pip install -r requirements.txt
```

#### 3.2 验证PyTorch安装
```bash
python -c "
import torch
import torchvision
print(f'PyTorch版本: {torch.__version__}')
print(f'TorchVision版本: {torchvision.__version__}')
print(f'CUDA可用: {torch.cuda.is_available()}')
"
```

### 步骤4: 模型准备

#### 4.1 检查模型文件
```bash
# 检查模型文件是否存在
ls -la checkpoints/best_model.pth

# 如果不存在，需要训练模型
python main.py train
```

#### 4.2 验证模型加载
```bash
# 测试模型信息
python main.py info --model_name resnet50
```

### 步骤5: 目录结构检查

确保以下目录结构存在：
```
ChestXRay/learn/
├── checkpoints/
│   └── best_model.pth          # 训练好的模型
├── static/
│   ├── uploads/                # 上传文件目录
│   └── reports/                # 报告保存目录
├── templates/                  # HTML模板
├── main.py                     # 主程序
├── web_app.py                 # Web应用
├── run_web.py                 # 启动脚本
├── requirements.txt           # 依赖文件
└── web_requirements.txt       # Web依赖
```

### 步骤6: 启动开发服务器

```bash
# 方法1: 使用启动脚本（推荐）
python run_web.py

# 方法2: 直接启动Flask
python web_app.py

# 方法3: 指定参数启动
python run_web.py --host 0.0.0.0 --port 8080
```

### 步骤7: 验证部署

1. 打开浏览器访问: http://localhost:5000
2. 上传测试X光片图像
3. 检查分析结果和报告生成

---

## 🚀 生产环境部署

### 步骤1: 服务器准备

#### 1.1 系统更新
```bash
# Ubuntu/Debian
sudo apt update && sudo apt upgrade -y

# CentOS/RHEL
sudo yum update -y
```

#### 1.2 安装系统依赖
```bash
# Ubuntu/Debian
sudo apt install -y python3 python3-pip python3-venv git nginx supervisor

# CentOS/RHEL
sudo yum install -y python3 python3-pip git nginx supervisor
```

### 步骤2: 应用部署

#### 2.1 创建应用目录
```bash
sudo mkdir -p /opt/chestxray-ai
sudo chown $USER:$USER /opt/chestxray-ai
cd /opt/chestxray-ai
```

#### 2.2 部署应用代码
```bash
# 复制代码
cp -r /path/to/ChestXRay/learn/* /opt/chestxray-ai/

# 创建虚拟环境
python3 -m venv venv
source venv/bin/activate

# 安装依赖
pip install --upgrade pip
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
pip install -r web_requirements.txt

# 安装生产环境WSGI服务器
pip install gunicorn
```

### 步骤3: 创建生产启动脚本

#### 3.1 创建Gunicorn配置
```bash
cat > /opt/chestxray-ai/gunicorn.conf.py << 'EOF'
# Gunicorn配置文件
bind = "127.0.0.1:5000"
workers = 4
worker_class = "sync"
worker_connections = 1000
max_requests = 1000
max_requests_jitter = 50
timeout = 300
keepalive = 2
preload_app = True
chdir = "/opt/chestxray-ai"
user = "www-data"
group = "www-data"

# 日志配置
accesslog = "/var/log/chestxray-ai/access.log"
errorlog = "/var/log/chestxray-ai/error.log"
loglevel = "info"

# 进程命名
proc_name = "chestxray-ai"
EOF
```

#### 3.2 创建启动脚本
```bash
cat > /opt/chestxray-ai/start.sh << 'EOF'
#!/bin/bash
cd /opt/chestxray-ai
source venv/bin/activate
exec gunicorn -c gunicorn.conf.py web_app:app
EOF

chmod +x /opt/chestxray-ai/start.sh
```

### 步骤4: 配置系统服务

#### 4.1 创建Systemd服务
```bash
sudo cat > /etc/systemd/system/chestxray-ai.service << 'EOF'
[Unit]
Description=ChestXRay AI Analysis System
After=network.target

[Service]
Type=exec
User=www-data
Group=www-data
WorkingDirectory=/opt/chestxray-ai
Environment=PATH=/opt/chestxray-ai/venv/bin
ExecStart=/opt/chestxray-ai/start.sh
ExecReload=/bin/kill -s HUP $MAINPID
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF
```

#### 4.2 启动服务
```bash
# 创建日志目录
sudo mkdir -p /var/log/chestxray-ai
sudo chown www-data:www-data /var/log/chestxray-ai

# 设置权限
sudo chown -R www-data:www-data /opt/chestxray-ai

# 启动服务
sudo systemctl daemon-reload
sudo systemctl enable chestxray-ai
sudo systemctl start chestxray-ai

# 检查状态
sudo systemctl status chestxray-ai
```

### 步骤5: 配置Nginx反向代理

#### 5.1 创建Nginx配置
```bash
sudo cat > /etc/nginx/sites-available/chestxray-ai << 'EOF'
server {
    listen 80;
    server_name your-domain.com;  # 替换为实际域名
    
    # 文件上传大小限制
    client_max_body_size 20M;
    
    # 静态文件
    location /static {
        alias /opt/chestxray-ai/static;
        expires 1d;
        add_header Cache-Control "public, immutable";
    }
    
    # 主应用
    location / {
        proxy_pass http://127.0.0.1:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_connect_timeout 300;
        proxy_send_timeout 300;
        proxy_read_timeout 300;
        send_timeout 300;
    }
    
    # 健康检查
    location /health {
        proxy_pass http://127.0.0.1:5000/health;
        access_log off;
    }
}
EOF
```

#### 5.2 启用站点
```bash
# 启用站点
sudo ln -s /etc/nginx/sites-available/chestxray-ai /etc/nginx/sites-enabled/

# 测试配置
sudo nginx -t

# 重启Nginx
sudo systemctl restart nginx
```

### 步骤6: HTTPS配置 (推荐)

#### 6.1 安装Certbot
```bash
sudo apt install certbot python3-certbot-nginx
```

#### 6.2 获取SSL证书
```bash
sudo certbot --nginx -d your-domain.com
```

---

## 🦙 Ollama配置

### 步骤1: 安装Ollama

#### 1.1 Linux/macOS安装
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### 1.2 Windows安装
从 https://ollama.ai/download/windows 下载安装包

#### 1.3 验证安装
```bash
ollama --version
```

### 步骤2: 配置Ollama服务

#### 2.1 启动Ollama服务
```bash
# 前台运行（测试）
ollama serve

# 后台服务
systemctl start ollama  # Linux
```

#### 2.2 下载医学模型
```bash
# 推荐模型（按优先级）
ollama pull llama3.1:8b     # 高质量通用模型
ollama pull llama2:7b       # 稳定中型模型
ollama pull gemma:7b        # Google模型

# 查看已安装模型
ollama list
```

### 步骤3: 生产环境Ollama配置

#### 3.1 创建Ollama用户
```bash
sudo useradd -r -s /bin/false ollama
```

#### 3.2 配置Systemd服务
```bash
sudo cat > /etc/systemd/system/ollama.service << 'EOF'
[Unit]
Description=Ollama Service
After=network.target

[Service]
Type=exec
User=ollama
Group=ollama
ExecStart=/usr/local/bin/ollama serve
Environment=OLLAMA_HOST=127.0.0.1:11434
Environment=OLLAMA_MODELS=/opt/ollama/models
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
EOF

# 创建模型目录
sudo mkdir -p /opt/ollama/models
sudo chown ollama:ollama /opt/ollama/models

# 启动服务
sudo systemctl enable ollama
sudo systemctl start ollama
```

### 步骤4: 测试Ollama集成

```bash
cd /opt/chestxray-ai
source venv/bin/activate

# 测试Ollama连接
python test_ollama.py

# 测试多模态AI
python test_multimodal.py
```

---

## ✅ 功能验证

### 1. 系统健康检查

```bash
# Web应用健康检查
curl http://localhost/health

# 预期响应
{
  "status": "healthy",
  "ai_systems": {
    "initialization_status": "success",
    "multimodal_available": true,
    "basic_predictor_available": true
  }
}
```

### 2. API测试

```bash
# 测试文件上传
curl -X POST -F "file=@test_image.jpg" -F "use_ollama=true" \
     http://localhost/upload
```

### 3. 用户界面测试

1. **访问主页**: http://your-domain.com
2. **上传测试**: 选择测试X光片
3. **切换模式**: 测试Ollama/增强版报告切换
4. **结果验证**: 确认报告正常生成

### 4. 性能测试

```bash
# 使用Apache Bench测试
ab -n 100 -c 10 http://localhost/

# 使用wrk测试
wrk -t12 -c400 -d30s http://localhost/
```

---

## 🔧 故障排除

### 常见问题及解决方案

#### 1. AI系统未初始化
```bash
# 症状：AI系统未初始化
# 检查模型文件
ls -la checkpoints/best_model.pth

# 重新训练模型
python main.py train

# 检查日志
tail -f /var/log/chestxray-ai/error.log
```

#### 2. Ollama连接失败
```bash
# 检查Ollama服务
systemctl status ollama

# 检查端口
netstat -tlnp | grep 11434

# 测试连接
curl http://localhost:11434/api/version
```

#### 3. 文件上传失败
```bash
# 检查权限
sudo chown -R www-data:www-data /opt/chestxray-ai/static

# 检查磁盘空间
df -h

# 检查Nginx配置
nginx -t
```

#### 4. 内存不足
```bash
# 监控内存使用
htop
free -m

# 调整Gunicorn workers
# 编辑 gunicorn.conf.py
workers = 2  # 减少worker数量
```

### 日志位置

| 组件 | 日志位置 | 说明 |
|------|----------|------|
| **应用** | `/var/log/chestxray-ai/error.log` | 应用错误日志 |
| **访问** | `/var/log/chestxray-ai/access.log` | 访问日志 |
| **Nginx** | `/var/log/nginx/error.log` | Nginx错误 |
| **系统** | `/var/log/syslog` | 系统日志 |

---

## ⚡ 性能优化

### 1. 应用层优化

#### 1.1 模型预加载
```python
# 在web_app.py中添加
from werkzeug.middleware.profiler import ProfilerMiddleware
app.wsgi_app = ProfilerMiddleware(app.wsgi_app)
```

#### 1.2 缓存配置
```python
from flask_caching import Cache

# 配置缓存
app.config['CACHE_TYPE'] = 'redis'
app.config['CACHE_REDIS_URL'] = 'redis://localhost:6379'
cache = Cache(app)
```

### 2. 系统层优化

#### 2.1 调整文件句柄限制
```bash
# 编辑 /etc/security/limits.conf
* soft nofile 65535
* hard nofile 65535
```

#### 2.2 内核参数优化
```bash
# 编辑 /etc/sysctl.conf
net.core.somaxconn = 1024
net.ipv4.tcp_max_syn_backlog = 2048
```

### 3. 数据库优化（如果使用）

```bash
# Redis优化
echo 'vm.overcommit_memory = 1' >> /etc/sysctl.conf
sysctl vm.overcommit_memory=1
```

---

## 📊 监控与维护

### 1. 系统监控

#### 1.1 安装Prometheus + Grafana
```bash
# 安装Prometheus
wget https://github.com/prometheus/prometheus/releases/download/v2.37.0/prometheus-2.37.0.linux-amd64.tar.gz
tar xvfz prometheus-*.tar.gz
sudo mv prometheus-2.37.0.linux-amd64 /opt/prometheus

# 配置监控
cat > /opt/prometheus/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'chestxray-ai'
    static_configs:
      - targets: ['localhost:5000']
    metrics_path: '/metrics'
    scrape_interval: 5s
EOF
```

#### 1.2 监控指标
- **CPU使用率**
- **内存使用率**
- **磁盘I/O**
- **网络流量**
- **响应时间**
- **错误率**

### 2. 日志管理

#### 2.1 日志轮转
```bash
# 创建logrotate配置
sudo cat > /etc/logrotate.d/chestxray-ai << 'EOF'
/var/log/chestxray-ai/*.log {
    daily
    missingok
    rotate 52
    compress
    notifempty
    create 0644 www-data www-data
    postrotate
        systemctl reload chestxray-ai
    endscript
}
EOF
```

#### 2.2 集中日志收集
```bash
# 使用ELK Stack或Fluentd
# 配置日志转发到中央日志服务器
```

### 3. 自动化运维

#### 3.1 健康检查脚本
```bash
cat > /opt/scripts/health_check.sh << 'EOF'
#!/bin/bash
# 健康检查脚本

URL="http://localhost/health"
RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" $URL)

if [ $RESPONSE -eq 200 ]; then
    echo "$(date): Service is healthy"
else
    echo "$(date): Service is unhealthy, response: $RESPONSE"
    systemctl restart chestxray-ai
fi
EOF

chmod +x /opt/scripts/health_check.sh

# 添加到crontab
echo "*/5 * * * * /opt/scripts/health_check.sh >> /var/log/health_check.log" | crontab -
```

---

## 🔒 安全配置

### 1. 防火墙配置

```bash
# UFW配置
sudo ufw allow 22/tcp      # SSH
sudo ufw allow 80/tcp      # HTTP
sudo ufw allow 443/tcp     # HTTPS
sudo ufw deny 5000/tcp     # 拒绝直接访问应用端口
sudo ufw deny 11434/tcp    # 拒绝直接访问Ollama端口
sudo ufw enable
```

### 2. SSL/TLS强化

```bash
# Nginx SSL配置增强
ssl_protocols TLSv1.2 TLSv1.3;
ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
ssl_prefer_server_ciphers off;
add_header Strict-Transport-Security "max-age=63072000" always;
```

### 3. 应用安全

```python
# 在web_app.py中添加安全头
from flask_talisman import Talisman

Talisman(app, {
    'force_https': True,
    'content_security_policy': {
        'default-src': "'self'",
        'script-src': "'self' 'unsafe-inline'",
        'style-src': "'self' 'unsafe-inline'"
    }
})
```

---

## 💾 备份与恢复

### 1. 数据备份

#### 1.1 模型文件备份
```bash
#!/bin/bash
# 备份脚本
BACKUP_DIR="/backup/chestxray-ai"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR/$DATE

# 备份模型文件
cp /opt/chestxray-ai/checkpoints/best_model.pth $BACKUP_DIR/$DATE/

# 备份配置文件
cp -r /opt/chestxray-ai/*.py $BACKUP_DIR/$DATE/
cp -r /opt/chestxray-ai/templates $BACKUP_DIR/$DATE/

# 压缩备份
tar -czf $BACKUP_DIR/backup_$DATE.tar.gz -C $BACKUP_DIR $DATE/
rm -rf $BACKUP_DIR/$DATE

echo "Backup completed: $BACKUP_DIR/backup_$DATE.tar.gz"
```

#### 1.2 自动备份
```bash
# 添加到crontab
0 2 * * * /opt/scripts/backup.sh
```

### 2. 灾难恢复

#### 2.1 恢复流程
1. 重新部署基础环境
2. 恢复应用代码和模型
3. 重启服务
4. 验证功能

#### 2.2 恢复脚本
```bash
#!/bin/bash
# 恢复脚本
BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# 停止服务
systemctl stop chestxray-ai

# 恢复文件
tar -xzf $BACKUP_FILE -C /opt/chestxray-ai/

# 设置权限
chown -R www-data:www-data /opt/chestxray-ai

# 启动服务
systemctl start chestxray-ai

echo "Recovery completed"
```

---

## ❓ FAQ

### Q1: 如何更新模型？
**A**: 
1. 备份现有模型
2. 训练新模型: `python main.py train`
3. 重启服务: `systemctl restart chestxray-ai`

### Q2: 如何增加并发处理能力？
**A**:
1. 增加Gunicorn workers
2. 配置负载均衡器
3. 使用Redis缓存
4. 考虑微服务架构

### Q3: 如何处理大文件上传？
**A**:
1. 调整Nginx `client_max_body_size`
2. 增加Flask `MAX_CONTENT_LENGTH`
3. 配置适当的超时时间

### Q4: Ollama模型占用空间太大怎么办？
**A**:
1. 选择较小的模型如 `llama2:7b`
2. 定期清理未使用的模型
3. 配置模型存储位置

### Q5: 如何监控系统性能？
**A**:
1. 使用Prometheus + Grafana
2. 配置日志监控
3. 设置告警规则
4. 定期性能测试

---

## 📞 技术支持

### 联系方式
- **技术文档**: 查看项目README.md
- **问题报告**: 通过GitHub Issues
- **邮件支持**: support@example.com

### 社区资源
- **官方文档**: https://pytorch.org/docs/
- **Ollama文档**: https://ollama.ai/docs/
- **Flask文档**: https://flask.palletsprojects.com/

---

## 📄 许可证

本项目遵循 MIT 许可证。详见 LICENSE 文件。

---

**⚠️ 免责声明**: 本系统仅供研究和教育用途。在医疗环境中使用前，请确保符合相关法规要求，并经过专业医生验证。

---

*文档版本: v1.0 | 最后更新: 2025年1月* 